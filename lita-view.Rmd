---
title: "LITA Tweets"
author: "James L. Adams"
output: html_document
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(DT)
library(ggthemes)
library(lubridate)
library(plotly)
library(stringr)
library(tidytext)
library(tidyverse)

# Get list of files
files_raw <- list.files("~/OneDrive - Dartmouth College/lita-tweets", pattern = "*-raw.csv", full.names = TRUE)

# Read each of those files with specified column types to help avoid errors
tweets_raw <- lapply(files_raw, read_csv, col_types = cols(id_str = col_character(),
                                                           in_reply_to_user_id_str = col_character(),
                                                           in_reply_to_status_id_str = col_character(),
                                                           user_id_str = col_character()
                                                           )
                     )
# Bind all of the data frames together
df_raw <- bind_rows(tweets_raw)

# Clean up the date/time from Twitter's weird format, keep only relevant variables
df <- df_raw %>%
  mutate(created_gmt = as.POSIXct(created_at, 
                              format="%a %b %d %H:%M:%S +0000 %Y", 
                              tz="GMT", 
                              origin="1970-01-01"
                              ),
         is_retweet = str_detect(text, "RT @")
         ) %>%
  mutate(created = with_tz(created_gmt, "America/Chicago")) %>%
  select(screen_name, id_str, created, text, lang, geo_enabled, retweet_count, time_zone, is_retweet)

# All the data frames!!!!!!
# Tweets, retweets, users, and unique by day
tweets_retweets_day <- df %>%
  group_by(day = date(created)) %>%
  summarize(users = length(unique(screen_name)), tweets = length(text), retweets = sum(as.numeric(is_retweet))) %>%
  mutate(unique = tweets-retweets) %>%
  gather(variable, value, -day)

# Tweets, retweets, users, and unique by day and time
tweets_retweets_time <- df %>%
  group_by(day = date(created), time = floor_date(created, unit = "hours")) %>%
  summarize(users = length(unique(screen_name)), tweets = length(text), retweets = sum(as.numeric(is_retweet))) %>%
  mutate(unique = tweets-retweets) %>%
  gather(variable, value, -time, -day)

# Tokenize words and remove stop words
df_tidy <- df %>%
  unnest_tokens(output = word, input = text) %>%
  anti_join(stop_words)

# Get 10 most common words, remove things like "https" that are clearly for links
# Making the word column a factor makes it easier to make a pretty, sorted column graph later
df_common_words <- table(df_tidy$word) %>%
  as_data_frame() %>%
  filter(!(Var1 %in% c("https", "t.co", "rt", "amp"))) %>%
  arrange(desc(n)) %>%
  head(n = 10) %>%
  mutate(word = factor(Var1, levels = Var1)) %>%
  select(word, n)

# Attach sentiments and emotions to tokenized words
df_sentiment <- df_tidy %>%
  left_join(get_sentiments(lexicon = "nrc")) %>%
  filter(!is.na(sentiment)) %>%
  group_by(sentiment, day = wday(created, label = TRUE), time = floor_date(created, unit = "hours")) %>%
  summarize(frequency = n()) %>%
  arrange(desc(frequency))

# Emotions by day
sent_day_specific <- df_sentiment %>%
  filter(!(sentiment %in% c("positive", "negative"))) %>%
  group_by(day, sentiment) %>%
  summarize(frequency = sum(frequency))

# Sentiments by day
sent_day_generic <- df_sentiment %>%
  filter((sentiment %in% c("positive", "negative"))) %>%
  group_by(day, sentiment) %>%
  summarize(frequency = sum(frequency))

# Emotions by time
sent_time_specific <- df_sentiment %>%
  filter(!(sentiment %in% c("positive", "negative")))

# Sentiments by time
sent_time_generic <- df_sentiment %>%
  filter((sentiment %in% c("positive", "negative")))

```

## LITA Forum 2016 {.tabset}

This is how tweets on the #litaforum hashtag break down, and how they look when their words are mapped to the [NRC Word-Emotion Association Lexicon](http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm). You can also download the raw data and mess around with it yourself.

Code is available on [GitHub](http://github.com/jladams/lita-view). Tweets have been gathered using Twitter's streaming API and the streamR package for R. Data has been recorded at half-hour intervals whenever my laptop has been open since Thursday afternoon, so hopefully there won't be too many gaps!

Last updated `r stamp("Tuesday, November 15, 2016 at 1:07 Central Time")(now())`. 

### Overview

Some basic stats for \#litaforum:

* `r length(df$text)` total tweets
* `r sum(tweets_retweets_day$value[tweets_retweets_day$variable == "tweets"])-sum(tweets_retweets_day$value[tweets_retweets_day$variable == "retweets"])` unique tweets
* `r sum(tweets_retweets_day$value[tweets_retweets_day$variable == "retweets"])` retweets
* `r length(unique(df$screen_name))` unique users tweeting

#### Most Popular Terms
```{r pop_words, echo = FALSE}
word_plot <- ggplot(df_common_words, aes(x = word, y = n)) +
  geom_bar(fill = "#12887d", stat = "identity") +
  theme_hc() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) +
  labs(x = "")

ggplotly(word_plot)
```

--------

#### Total Tweets and Users
```{r overview, echo = FALSE}
users_day_plot <- ggplot(tweets_retweets_day[tweets_retweets_day$variable %in% c("tweets", "users"),], aes(x = day, y = value, color = variable)) +
  geom_line() +
  geom_point() +
  theme_hc() +
  scale_color_hc() +
  labs(x = "Date", y = "", title = "By Day")

users_time_plot <- ggplot(tweets_retweets_time[tweets_retweets_time$variable %in% c("tweets", "users"),], aes(x = hour(time), y = value, color = variable, group = variable)) +
  geom_line() +
  geom_point() +
  theme_hc() +
  scale_color_hc() +
  labs(x = "Time (America/Chicago)", y = "", title = "By Time") +
  facet_grid(day~.) +
  scale_x_continuous(labels = format(unique(tweets_retweets_time$time), "%H:%M"))

ggplotly(users_day_plot)
ggplotly(users_time_plot) %>% layout(legend = list(x = 1.05, y = 1))

```

------

#### Unique Tweets and Retweets
```{r retweets, echo = FALSE}
retweets_day_plot <- ggplot(tweets_retweets_day[tweets_retweets_day$variable %in% c("unique", "retweets"),], aes(x = day, y = value, color = variable)) +
  geom_line() +
  geom_point() +
  theme_hc() +
  scale_color_hc() +
  labs(x = "Date", y = "", title = "By Day")

retweets_time_plot <- ggplot(tweets_retweets_time[tweets_retweets_time$variable %in% c("unique", "retweets"),], aes(x = hour(time), y = value, color = variable)) +
  geom_line() +
  geom_point() +
  theme_hc() +
  scale_color_hc() +
  labs(x = "Time (America/Chicago)", y = "", title = "By Time") +
  facet_grid(day~.) +
  scale_x_continuous(labels = format(unique(tweets_retweets_time$time), "%H:%M"))

ggplotly(retweets_day_plot)
ggplotly(retweets_time_plot) %>% layout(legend = list(x = 1.05, y = 1))
```


### Sentiment/Emotion Frequency by Day

```{r sent_day, echo = FALSE}
sentiment_freq_generic <- ggplot(sent_day_generic, aes(x = sentiment, y = frequency)) +
  geom_bar(aes(fill = sentiment), stat = "identity") +
  facet_grid(.~day) +
  theme_hc() +
  scale_fill_hc(guide = FALSE) +
  geom_text(aes(label = frequency), vjust = 0) +
  labs(title = "Positive vs. Negative", x = "")


sentiment_freq_specific <- ggplot(sent_day_specific, aes(x = sentiment, y = frequency)) +
  geom_bar(aes(fill = sentiment), stat = "identity") +
  facet_wrap(~ day) +
  theme_hc() +
  scale_fill_economist(guide = FALSE) +
  geom_text(aes(label = frequency), vjust = 0) +
  labs(title = "Specific Emotions", x = "") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5))

print(sentiment_freq_generic)
print(sentiment_freq_specific)

```

### Sentiment/Emotion Frequency by Time
```{r sent_time, echo = FALSE}
sent_lines_generic <- ggplot(sent_time_generic, aes(x = hour(time), y = frequency)) +
  geom_line(aes(color = sentiment, group = sentiment)) +
  geom_point(aes(color = sentiment)) +
  facet_grid(day~.) +
  theme_hc() +
  scale_color_hc() +
  labs(title = "Positive vs. Negative", x = "Time (America/Chicago)") +
  scale_x_continuous(labels = format(unique(tweets_retweets_time$time), "%H:%M"))


sent_lines_specific <- ggplot(sent_time_specific, aes(x = hour(time), y = frequency)) +
  geom_line(aes(color = sentiment, group = sentiment)) +
  geom_point(aes(color = sentiment)) +
  facet_grid(day~.) +
  theme_hc() +
  scale_color_economist() +
  labs(title = "Specific Emotions", x = "Time (America/Chicago)") +
  theme(legend.position = "bottom") +
  scale_x_continuous(labels = format(unique(tweets_retweets_time$time), "%H:%M"))

ggplotly(sent_lines_generic) %>% layout(legend = list(x = 1.05, y = 1))
ggplotly(sent_lines_specific) %>% layout(legend = list(x = 1.05, y = 1))

```

### Raw Data
```{r data, echo = FALSE}
datatable(df_raw, 
          class = "cell-border stripe", 
          escape = FALSE, extensions = "Buttons", 
          options = list(dom = "Bfrtip", 
                         buttons = c("csv", "excel", "pdf"),
                         order = list(4, "desc")
                         ), 
          rownames = FALSE
          )
```
